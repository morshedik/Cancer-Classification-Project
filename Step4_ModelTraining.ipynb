{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZkXy0uQLScr2wKnDoXy/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morshedik/Cancer-Classification-Project/blob/main/Step4_ModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvk41moSX2sN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/TCGA_Data\""
      ],
      "metadata": {
        "id": "k_XSJstbmHqE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "F0F_-g_A1-wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/TCGA_Data/preprocessed_data.csv'\n",
        "preprocessed_data = pd.read_csv(data_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = preprocessed_data.drop(columns=['sample', 'primary_disease'])\n",
        "y = preprocessed_data['primary_disease']\n",
        "\n",
        "# Split into train and test (you already did this, but let’s confirm)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check shapes\n",
        "print(\"Training Set Shape:\", X_train.shape)  # Should be (1848, 100)\n",
        "print(\"Testing Set Shape:\", X_test.shape)    # Should be (463, 100)\n",
        "print(\"Training Labels Sample:\", y_train.head())\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "# Create the model (multi_class='ovr' for one-vs-rest)\n",
        "model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
        "# Train on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print a confirmation\n",
        "print(\"Model trained successfully!\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print some predictions\n",
        "print(\"Sample Predictions:\")\n",
        "for i in range(5):\n",
        "    print(f\"Sample {i}: Predicted {y_pred[i]}, Actual {y_test.iloc[i]}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Test Set: {accuracy:.2f}\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix for Cancer Classification\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D6WeQPH7mbwT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified model\n"
      ],
      "metadata": {
        "id": "HSm1cz5hMIHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load data(top 100 high variance genes)\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/TCGA_Data/preprocessed_data.csv'\n",
        "preprocessed_data = pd.read_csv(data_path)\n",
        "# Separate features and labels\n",
        "X = preprocessed_data.drop(columns=['sample', 'primary_disease'])\n",
        "y = preprocessed_data['primary_disease']\n",
        "\n",
        "# Split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train accuracy (check for overfitting)\n",
        "model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
        "model.fit(X_train, y_train)\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Model Accuracy on Training Set: {train_accuracy:.2f}\")\n",
        "\n",
        "# Test accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on Test Set: {test_accuracy:.2f}\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
        "print(f\"Average CV Accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n",
        "\n",
        "# Feature scaling and re-train\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model_scaled = LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Model Accuracy on Scaled Test Set: {accuracy_scaled:.2f}\")\n",
        "\n",
        "# Regularization (try C=0.1)\n",
        "model_regularized = LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42, C=0.1)\n",
        "model_regularized.fit(X_train, y_train)\n",
        "y_pred_regularized = model_regularized.predict(X_test)\n",
        "accuracy_regularized = accuracy_score(y_test, y_pred_regularized)\n",
        "print(f\"Model Accuracy with Regularization (C=0.1): {accuracy_regularized:.2f}\")\n",
        "\n",
        "# Check for data leakage\n",
        "train_samples = set(X_train.index)\n",
        "test_samples = set(X_test.index)\n",
        "overlap = train_samples.intersection(test_samples)\n",
        "print(f\"Number of Overlapping Samples: {len(overlap)}\")\n",
        "if len(overlap) > 0:\n",
        "    print(\"Overlapping Samples:\", overlap)\n",
        "\n",
        "# Confusion matrix (optional, for insight)\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix for Cancer Classification\")\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, '/content/drive/My Drive/Colab Notebooks/TCGA_Data/cancer_classifier_step4.pkl')\n",
        "print(\"Model saved to Google Drive.\")"
      ],
      "metadata": {
        "id": "o0Eee_ivmq8g",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perfect Accuracy Explanation\n",
        "The model achieves 100% accuracy due to strong biological signals, such as KLK3 (high in prostate adenocarcinoma) and SFTPB (high in lung adenocarcinoma), which create clear separation among BRCA, LUAD, and PRAD. This is supported by visualizations (e.g., expression scatter plots) and mean expression differences (KLK3: 18.23 PRAD vs. 1.39 BRCA, 0.36 LUAD). However, to rule out overfitting or artifacts (e.g., batch effects), we will validate on external data in Step 5."
      ],
      "metadata": {
        "id": "7qluvnsmHfvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overfitting Check"
      ],
      "metadata": {
        "id": "OkyrBYFC7la1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean Expression by Cancer Type for KLK3:\")\n",
        "print(preprocessed_data.groupby('primary_disease')['KLK3'].mean())\n",
        "\n",
        "print(\"Test Set Class Distribution:\")\n",
        "print(y_test.value_counts())\n",
        "\n",
        "import numpy as np\n",
        "correlation_matrix = X_train.corr()\n",
        "print(\"Correlation of Top 5 Features with KLK3:\")\n",
        "print(correlation_matrix['KLK3'].nlargest(5))\n",
        "\n",
        "# prompt: expression of TMEFF2 and KLK3 in different cancer types\n",
        "\n",
        "print(\"Mean Expression by Cancer Type for TMEFF2:\")\n",
        "print(preprocessed_data.groupby('primary_disease')['TMEFF2'].mean())\n",
        "\n",
        "print(\"Mean Expression by Cancer Type for KLK3:\")\n",
        "print(preprocessed_data.groupby('primary_disease')['KLK3'].mean())\n",
        "\n",
        "# Reduce to top 50 genes (less complex model)\n",
        "top_50_genes = X.var().nlargest(50).index\n",
        "X_50 = X[top_50_genes]\n",
        "X_train_50, X_test_50, y_train, y_test = train_test_split(X_50, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train and evaluate\n",
        "model_50 = LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42)\n",
        "model_50.fit(X_train_50, y_train)\n",
        "y_pred_50 = model_50.predict(X_test_50)\n",
        "accuracy_50 = accuracy_score(y_test, y_pred_50)\n",
        "print(f\"Model Accuracy with 50 Genes: {accuracy_50:.2f}\")\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Use OneVsRestClassifier (recommended for scikit-learn 1.5+)\n",
        "base_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_ovr = OneVsRestClassifier(base_lr)\n",
        "model_ovr.fit(X_train, y_train)\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n",
        "print(f\"Model Accuracy with OneVsRestClassifier: {accuracy_ovr:.2f}\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = X_train.corr()\n",
        "\n",
        "# Set threshold for correlation (e.g., >0.9)\n",
        "threshold = 0.9\n",
        "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "\n",
        "# Drop highly correlated features\n",
        "X_train_reduced = X_train.drop(to_drop, axis=1)\n",
        "X_test_reduced = X_test.drop(to_drop, axis=1)\n",
        "\n",
        "# Get coefficients from the OneVsRestClassifier (first classifier for BRCA vs. others)\n",
        "coef = model.estimators_[0].coef_[0]  # First class (BRCA) coefficients\n",
        "feature_importance = pd.DataFrame({'Gene': X_train.columns, 'Coefficient': coef})\n",
        "print(\"Top 10 Most Important Features for BRCA:\")\n",
        "print(feature_importance.sort_values(by='Coefficient', key=abs, ascending=False).head(10))\n",
        "\n",
        "# Train and evaluate\n",
        "model_reduced = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_reduced.fit(X_train_reduced, y_train)\n",
        "y_pred_reduced = model_reduced.predict(X_test_reduced)\n",
        "accuracy_reduced = accuracy_score(y_test, y_pred_reduced)\n",
        "print(f\"Model Accuracy with Reduced Features: {accuracy_reduced:.2f}\")\n",
        "print(\"Dropped Features:\", to_drop)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train with stronger regularization\n",
        "model_scaled_reg = LogisticRegression(max_iter=1000, C=0.01, random_state=42)\n",
        "model_scaled_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled_reg = model_scaled_reg.predict(X_test_scaled)\n",
        "accuracy_scaled_reg = accuracy_score(y_test, y_pred_scaled_reg)\n",
        "print(f\"Model Accuracy with Scaling and C=0.01: {accuracy_scaled_reg:.2f}\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reduce to 30 genes (simpler)\n",
        "top_30_genes = X.var().nlargest(30).index\n",
        "X_30 = X[top_30_genes]\n",
        "X_train_30, X_test_30, _, _ = train_test_split(X_30, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "model_30 = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_30.fit(X_train_30, y_train)\n",
        "y_pred_30 = model_30.predict(X_test_30)\n",
        "accuracy_30 = accuracy_score(y_test, y_pred_30)\n",
        "print(f\"Model Accuracy with 30 Genes: {accuracy_30:.2f}\")\n",
        "\n",
        "# Or use PCA (50 components)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "pca = PCA(n_components=50)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train_pca, X_test_pca, _, _ = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "model_pca = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = model_pca.predict(X_test_pca)\n",
        "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
        "print(f\"Model Accuracy with PCA (50 components): {accuracy_pca:.2f}\")\n",
        "\n",
        "# prompt: Look at sample IDs in your train and test sets. If any share the same first 12 characters (e.g., TCGA-2A-A8VL)\n",
        "\n",
        "# Check for overlapping sample IDs in train and test sets\n",
        "train_samples = set(X_train.index.astype(str).str[:12])\n",
        "test_samples = set(X_test.index.astype(str).str[:12])\n",
        "\n",
        "overlap = train_samples.intersection(test_samples)\n",
        "\n",
        "if overlap:\n",
        "    print(\"Overlapping sample IDs (first 12 characters):\")\n",
        "    for sample_id in overlap:\n",
        "        print(sample_id)\n",
        "else:\n",
        "    print(\"No overlapping sample IDs found in train and test sets.\")\n",
        "\n",
        "# prompt: Check metadata for batch IDs or sequencing platforms. If cancer types align with batches, the model might be learning artifacts.\n",
        "# Assuming 'preprocessed_data' DataFrame is already loaded\n",
        "# Check for metadata columns related to batches or sequencing platforms\n",
        "metadata_columns = ['batch_id', 'sequencing_platform', 'experiment_id']  # Add other relevant columns\n",
        "metadata_columns = [col for col in metadata_columns if col in preprocessed_data.columns]\n",
        "\n",
        "if metadata_columns:\n",
        "    print(\"Metadata columns found:\")\n",
        "    for col in metadata_columns:\n",
        "        print(col)\n",
        "\n",
        "        # Analyze relationship between metadata and cancer types\n",
        "        print(\"\\nDistribution of cancer types within each batch:\")\n",
        "        print(preprocessed_data.groupby(col)['primary_disease'].value_counts())\n",
        "\n",
        "        # Further analysis (e.g., chi-squared test) can be performed to check for statistically significant associations\n",
        "else:\n",
        "    print(\"No metadata columns related to batches or sequencing platform were found.\")\n",
        "\n",
        "    # prompt: Plot expression levels of top genes (e.g., KLK3, SFTPB) by cancer type. If there’s no overlap (e.g., PRAD’s KLK3 is always >10 while BRCA/LUAD is <2), perfect separation is likely.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'preprocessed_data' DataFrame is already loaded\n",
        "\n",
        "# Select the genes of interest\n",
        "genes = ['KLK3', 'SFTPB']  # Add other genes\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for gene in genes:\n",
        "    if gene in preprocessed_data.columns:  # Check if the gene exists in the dataframe\n",
        "        for cancer_type in preprocessed_data['primary_disease'].unique():\n",
        "            expression_levels = preprocessed_data[preprocessed_data['primary_disease'] == cancer_type][gene]\n",
        "            plt.scatter(\n",
        "                [cancer_type] * len(expression_levels),\n",
        "                expression_levels,\n",
        "                label=f\"{gene} ({cancer_type})\"\n",
        "            )\n",
        "\n",
        "plt.xlabel(\"Cancer Type\")\n",
        "plt.ylabel(\"Expression Level\")\n",
        "plt.title(\"Expression Levels of Top Genes by Cancer Type\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#separability with boxplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='primary_disease', y='KLK3', data=preprocessed_data)\n",
        "plt.title('KLK3 Expression by Cancer Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='primary_disease', y='SFTPB', data=preprocessed_data)\n",
        "plt.title('SFTPB Expression by Cancer Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(X_train.corr(), cmap='coolwarm', center=0, annot=False)\n",
        "plt.title('Correlation Heatmap of Top 100 Genes')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MbsHD1SUM68W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}