{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyXkLi6HHhif4Ar1yHKYan"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6481J9Oe53Z"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load preprocessed data\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/TCGA_Data/preprocessed_data.csv'\n",
        "preprocessed_data = pd.read_csv(data_path)\n",
        "\n",
        "# Load trained model from Step 4\n",
        "model_path = '/content/drive/My Drive/Colab Notebooks/TCGA_Data/cancer_classifier_step4.pkl'\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = preprocessed_data.drop(columns=['sample', 'primary_disease'])\n",
        "y = preprocessed_data['primary_disease']\n",
        "\n",
        "# Split (recreate to match Step 4)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Verify shapes\n",
        "print(\"Training Set Shape:\", X_train.shape)  # Should be (1848, 100)\n",
        "print(\"Testing Set Shape:\", X_test.shape)    # Should be (463, 100)\n",
        "print(\"Training Labels Sample:\", y_train.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wt_Lh2_khVob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model Performance"
      ],
      "metadata": {
        "id": "4AY_4mTG2aoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Classification report (precision, recall, F1-score)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['BRCA', 'LUAD', 'PRAD']))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['BRCA', 'LUAD', 'PRAD'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix for Cancer Classification (Step 5)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0aBHr0W2hjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot ROC Curves\n",
        "Assess Class-Specific Performance: ROC curves show trade-offs between true positive rate and false positive rate for each class."
      ],
      "metadata": {
        "id": "a5woY7or6RGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get prediction probabilities\n",
        "y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(3):  # Loop through BRCA, LUAD, PRAD\n",
        "    fpr, tpr, _ = roc_curve(y_test == model.classes_[i], y_pred_proba[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model.classes_[i]} (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for Cancer Classification')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i5EKuwUn6UF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore Feature Importance"
      ],
      "metadata": {
        "id": "lEUb9r2V7dxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Feature importance via permutation (robust for OneVsRestClassifier)\n",
        "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
        "feature_importance = pd.DataFrame({'Gene': X_test.columns, 'Importance': perm_importance.importances_mean})\n",
        "print(\"Top 10 Most Important Features Across Classes:\")\n",
        "print(feature_importance.sort_values(by='Importance', ascending=False).head(10))\n",
        "\n",
        "# Coefficients from first classifier (BRCA vs. others)\n",
        "coef = model.estimators_[0].coef_[0]  # BRCA coefficients\n",
        "feature_coef = pd.DataFrame({'Gene': X_train.columns, 'Coefficient': coef})\n",
        "print(\"\\nTop 10 Most Important Features for BRCA (Coefficients):\")\n",
        "print(feature_coef.sort_values(by='Coefficient', key=abs, ascending=False).head(10))"
      ],
      "metadata": {
        "id": "27zlLIgN7A1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importance of a feature is calculated by shuffling that feature's values and measuring the decrease in model performance (e.g., accuracy). Since your model is already perfectly accurate, shuffling any feature does not decrease the accuracy on the test set—it remains 100%. Thus, the importance is calculated as 0 for all features."
      ],
      "metadata": {
        "id": "xY2zS_H78zGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate with External Data"
      ],
      "metadata": {
        "id": "wBKHPARa9CqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load external data (example path)\n",
        "external_path = '/path/to/external_data.csv'\n",
        "external_data = pd.read_csv(external_path)\n",
        "X_external = external_data.drop(columns=['sample', 'primary_disease'])\n",
        "y_external = external_data['primary_disease']\n",
        "\n",
        "# Ensure same genes (match Step 4’s top 100)\n",
        "X_external = X_external[top_genes]  # Use top_genes from Step 4\n",
        "X_external_scaled = scaler.transform(X_external)  # Scale with Step 4 scaler\n",
        "\n",
        "# Predict\n",
        "y_pred_external = model.predict(X_external_scaled)\n",
        "accuracy_external = accuracy_score(y_external, y_pred_external)\n",
        "print(f\"Model Accuracy on External Data: {accuracy_external:.2f}\")"
      ],
      "metadata": {
        "id": "ikpFz5tg805Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_importance = pd.DataFrame({'Gene': X_train.columns, 'Importance': rf_model.feature_importances_})\n",
        "print(\"Random Forest Feature Importance:\")\n",
        "print(rf_importance.sort_values(by='Importance', ascending=False).head(10))"
      ],
      "metadata": {
        "id": "Yqu97GPc9ye5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}